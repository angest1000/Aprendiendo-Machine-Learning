{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librería que contiene las funciones necesarias\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función Sigmoide f(x)=1/(1+Exp[-x])\n",
    "\n",
    "def nonlin(x,deriv=False):\n",
    "    if (deriv==True):\n",
    "        return x*(1-x)\n",
    "    return 1/(1+np.exp(-x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1]\n",
      " [0 1 1]\n",
      " [1 0 1]\n",
      " [1 1 1]]\n",
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "#iniciando nuestro dataset \n",
    "#donde cada fila es un ejemplo de entrenamiento\n",
    "#y cada columna representa una neurona\n",
    "\n",
    "\n",
    "# en este ejemplo se tienen 4 ejemplos \n",
    "#de entrenamiento con 3 neuronas cada uno\n",
    "\n",
    "#input data\n",
    "X = np.array([[0,0,1],\n",
    "              [0,1,1],\n",
    "              [1,0,1],\n",
    "              [1,1,1]])\n",
    "\n",
    "y = np.array([ [0],\n",
    "               [1],\n",
    "               [1],\n",
    "               [0]])\n",
    "\n",
    "print X \n",
    "print y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se generan números aleatorios con \n",
    "#la misma semilla para fines de \n",
    "#que la depuracion sea mas facil\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.1653904   0.11737966 -0.71922612 -0.60379702]\n",
      " [ 0.60148914  0.93652315 -0.37315164  0.38464523]\n",
      " [ 0.7527783   0.78921333 -0.82991158 -0.92189043]]\n",
      "[[-0.66033916]\n",
      " [ 0.75628501]\n",
      " [-0.80330633]\n",
      " [-0.15778475]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#se crea la sinapsis\n",
    "#al tener 3 capas en nuestra red necesitamos 2 matrices \n",
    "#de sinapsis con pesos asignados aleatoriamente\n",
    "\n",
    "#synapses\n",
    "syn0=2*np.random.random((3,4))-1\n",
    "syn1=2*np.random.random((4,1))-1\n",
    "\n",
    "print syn0\n",
    "print syn1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.49641003190272537\n",
      "Error: 0.008584525653247153\n",
      "Error: 0.0057894598625078085\n",
      "Error: 0.004629176776769985\n",
      "Error: 0.003958765280273649\n",
      "Error: 0.003510122567861679\n",
      "Error: 0.0031835023858748273\n",
      "Error: 0.0029323063422830725\n",
      "Error: 0.0027315064182105073\n",
      "Error: 0.0025663172400400254\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#código de entrenamiento\n",
    "#el ciclo for recorrerá el código para optimizar \n",
    "#la red para el dataset dado\n",
    "\n",
    "\n",
    "#la primer capa es solo para insertar información\n",
    "\n",
    "#el paso de prediccion efecuará la multiplicación\n",
    "#de matrices entre capa y sinapsis\n",
    "\n",
    "#luego se usa el sigmoide en todos los valores\n",
    "#para crear la siguiente capa\n",
    "#y se repite el proceso para conseguir la próxima capa\n",
    "#mejorando la predicción\n",
    "\n",
    "#y se compara con la salida esperada\n",
    "#restando para extraer el ratio de error\n",
    "   \n",
    "#train step\n",
    "for j in xrange(100000):\n",
    "    \n",
    "    l0=X\n",
    "    l1=nonlin(np.dot(l0,syn0))\n",
    "    l2=nonlin(np.dot(l1,syn1))\n",
    "    \n",
    "    l2_error=y-l2\n",
    "    \n",
    "    if(j%10000)==0:\n",
    "        print \"Error: \" + str(np.mean(np.abs(l2_error))) #para ver como se comporta el error\n",
    "        \n",
    "    #Comienza el Backpropagation\n",
    "    l2_delta= l2_error*nonlin(l2,deriv=True)\n",
    "    \n",
    "    l1_error=l2_delta.dot(syn1.T)\n",
    "    \n",
    "    l1_delta=l1_error*nonlin(l1,deriv=True)\n",
    "    \n",
    "    #Actualiza los pesos de  forma aleatoria\n",
    "    #update weights\n",
    "    syn1 +=l1.T.dot(l2_delta)\n",
    "    syn0+=l0.T.dot(l1_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Salida después del entrenamiento:\n",
      "[[0.00199094]\n",
      " [0.99751458]\n",
      " [0.99771098]\n",
      " [0.00294418]]\n"
     ]
    }
   ],
   "source": [
    "print \"\\nSalida después del entrenamiento:\"\n",
    "print l2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
